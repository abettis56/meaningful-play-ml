{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meaningful Play Score Assigner\n",
    "\n",
    "This program is designed to take an adjacency matrix of a topology of non-looping, non-backtracking linear choices, and apply q-learning to determine how meaningful the set of choices would be from the perspective of the actor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Initial set up before we begin:\n",
    "\n",
    "#### Import Statements\n",
    "\n",
    "Here all libraries that we use will be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather User Input\n",
    "\n",
    "We'll need to know the input file for the adjacency matrix and the number of layers\n",
    "\n",
    "TODO: (Can modify layer and ending counts to be automatically calculated from adjacency matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the name of the topology .txt file you want to score: SteinsGateMatrix.txt\n",
      "Please input the number of non-ending layers your topology has: 57\n",
      "Please input the number of endings in your topology: 6\n"
     ]
    }
   ],
   "source": [
    "filename = input(\"Please input the name of the topology .txt file you want to score: \")\n",
    "layers = int(input(\"Please input the number of non-ending layers your topology has: \"))\n",
    "endings = int(input(\"Please input the number of endings in your topology: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create State Mapping\n",
    "\n",
    "The states need to be put into a map for identification purposes.\n",
    "\n",
    "TODO:(Can automate this step based on information from the adjacency matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG\n"
     ]
    }
   ],
   "source": [
    "#Mapping for the states of NoIntegrated.txt\n",
    "location_to_state = {\n",
    "    'Start' : 0,\n",
    "    '2a' : 1,\n",
    "    '2b' : 2,\n",
    "    '3' : 3,\n",
    "    '4a' : 4,\n",
    "    '4b' : 5,\n",
    "    '5' : 6,\n",
    "    '6a' : 7,\n",
    "    '6b' : 8,\n",
    "    '7': 9,\n",
    "    '8a' : 10,\n",
    "    '8b' : 11,\n",
    "    '9_Flag1' : 12,\n",
    "    '10_Flag' : 13,\n",
    "    '11_Flag' : 14,\n",
    "    '12_Flag' : 15,\n",
    "    '13_Flag' : 16,\n",
    "    '14_Flag' : 17,\n",
    "    '15_Flag' : 18,\n",
    "    '16_Flag_Check' : 19,\n",
    "    '17_True' : 20,\n",
    "    '18a_True' : 21,\n",
    "    '18b_True' : 22,\n",
    "    '19_Flag2' : 23,\n",
    "    '20_Flag' : 24,\n",
    "    '21_Flag_Check' : 25,\n",
    "    '22_True' : 26,\n",
    "    '23a_True' : 27,\n",
    "    '23b_True' : 28,\n",
    "    '24_True' : 29,\n",
    "    '25a_True' : 30,\n",
    "    '25b_True' : 31,\n",
    "    '26_BigSplit_True' : 32,\n",
    "    '27a_True' : 33,\n",
    "    '27b_True' : 34,\n",
    "    '27c_True' : 35,\n",
    "    '27d_True' : 36,\n",
    "    '28_Suzuha?_True' : 37,\n",
    "    '29_True' : 38,\n",
    "    '30_Flag3' : 39,\n",
    "    '31_Flag' : 40,\n",
    "    '32_Flag' : 41,\n",
    "    '33_Flag_Check' : 42,\n",
    "    '34_True' : 43,\n",
    "    '35a_True' : 44,\n",
    "    '35b_True' : 45,\n",
    "    '36_True' : 46,\n",
    "    '37a_True' : 47,\n",
    "    '37b_True' : 48,\n",
    "    '38_Faris?_True' : 49,\n",
    "    '39_Flag4' : 50,\n",
    "    '40_Flag' : 51,\n",
    "    '41_Flag_Check' : 52,\n",
    "    '42_True' : 53,\n",
    "    '43a_True' : 54,\n",
    "    '43b_True' : 55,\n",
    "    '44_Luka?_True' : 56,\n",
    "    '45_True' : 57,\n",
    "    '46_True' : 58,\n",
    "    '46b_True' : 59,\n",
    "    '46ba_True' : 60,\n",
    "    '46bb_True' : 61,\n",
    "    '47_True' : 62,\n",
    "    '48a_True' : 63,\n",
    "    '48b_True' : 64,\n",
    "    '49_Flag5' : 65,\n",
    "    '50_Flag' : 66,\n",
    "    '51_Flag_Check' : 67,\n",
    "    '52_True' : 68,\n",
    "    '53a_True' : 69,\n",
    "    '53b_True' : 70,\n",
    "    '54_Flag6' : 71,\n",
    "    '55_Flag_Check' : 72,\n",
    "    '56_True' : 73,\n",
    "    '57a_True' : 74,\n",
    "    '57b_True' : 75,\n",
    "    '10_Mayuri' : 76,\n",
    "    '11_Mayuri' : 77,\n",
    "    '12a_Mayuri' : 78,\n",
    "    '12b_Mayuri' : 79,\n",
    "    '13_Mayuri' : 80,\n",
    "    '14a_Mayuri' : 81,\n",
    "    '14b_Mayuri' : 82,\n",
    "    '15_Mayuri' : 83,\n",
    "    '16a_Mayuri' : 84,\n",
    "    '16b_Mayuri' : 85,\n",
    "    '17_Mayuri' : 86,\n",
    "    '18a_Mayuri' : 87,\n",
    "    '18b_Mayuri' : 88,\n",
    "    '18c_Mayuri' : 89,\n",
    "    '18d_Mayuri' : 90,\n",
    "    '19_Suzuha?_Mayuri' : 91,\n",
    "    '20_Mayuri' : 92,\n",
    "    '21_Mayuri' : 93,\n",
    "    '22a_Mayuri' : 94,\n",
    "    '22b_Mayuri' : 95,\n",
    "    '23_Mayuri' : 96,\n",
    "    '24a_Mayuri' : 97,\n",
    "    '24b_Mayuri' : 98,\n",
    "    '25_Faris?_Mayuri' : 99,\n",
    "    '26_Mayuri' : 100,\n",
    "    '27_Mayuri' : 101,\n",
    "    '28a_Mayuri' : 102,\n",
    "    '28b_Mayuri' : 103,\n",
    "    '30_Luka?_Mayuri' : 104,\n",
    "    '31_Mayuri' : 105,\n",
    "    '32b_Mayuri' : 106,\n",
    "    '33ba_Mayuri' : 107,\n",
    "    '33bb_Mayuri' : 108,\n",
    "    '32_Mayuri' : 109,\n",
    "    '33_Mayuri' : 110,\n",
    "    '34a_Mayuri' : 111,\n",
    "    '34b_Mayuri' : 112,\n",
    "    '35_Mayuri' : 113,\n",
    "    '36a_Mayuri' : 114,\n",
    "    '36b_Mayuri' : 115,\n",
    "    '37_Mayuri' : 116,\n",
    "    '38a_Mayuri' : 117,\n",
    "    '38b_Mayuri' : 118,\n",
    "    '20_Kurisu' : 119,\n",
    "    '13_Kurisu' : 120,\n",
    "    '14a_Kurisu' : 121,\n",
    "    '14b_Kurisu' : 122,\n",
    "    '15_Kurisu' : 123,\n",
    "    '16a_Kurisu' : 124,\n",
    "    '16b_Kurisu' : 125,\n",
    "    '17_Kurisu' : 126,\n",
    "    '18a_Kurisu' : 127,\n",
    "    '18b_Kurisu' : 128,\n",
    "    '18c_Kurisu' : 129,\n",
    "    '18d_Kurisu' : 130,\n",
    "    '20_Suzuha?_Kurisu' : 131,\n",
    "    '21_Kurisu' : 132,\n",
    "    '22_Point_Kurisu' : 133,\n",
    "    '23a_Kurisu' : 134,\n",
    "    '23b_Kurisu' : 135,\n",
    "    '24_Kurisu' : 136,\n",
    "    '25a_Kurisu' : 137,\n",
    "    '25b_Kurisu' : 138,\n",
    "    '26_Faris?_Kurisu' : 139,\n",
    "    '27_Kurisu' : 140,\n",
    "    '28_Point_Kurisu' : 141,\n",
    "    '29a_Kurisu' : 142,\n",
    "    '29b_Kurisu' : 143,\n",
    "    '30_Luka?_Kurisu' : 144,\n",
    "    '31_Kurisu' : 145,\n",
    "    '32b_Kurisu' : 146,\n",
    "    '33ba_Kurisu' : 147,\n",
    "    '33bb_Kurisu' : 148,\n",
    "    '32_Kurisu' : 149,\n",
    "    '33_Kurisu' : 150,\n",
    "    '34a_Kurisu' : 151,\n",
    "    '34b_Kurisu' : 152,\n",
    "    '35_Point_Kurisu' : 153,\n",
    "    '36a_Kurisu' : 154,\n",
    "    '36b_Kurisu' : 155,\n",
    "    '37_Point_Kurisu' : 156,\n",
    "    '38a_Kurisu' : 157,\n",
    "    '38b_Kurisu' : 158,\n",
    "    'E1' : 159,\n",
    "    'E2' : 160,\n",
    "    'E3' : 161,\n",
    "    'E4' : 162,\n",
    "    'E5' : 163,\n",
    "    'E6' : 164\n",
    "}\n",
    "\n",
    "# Map indices to locations\n",
    "state_to_location = dict((state,location) for location,state in location_to_state.items())\n",
    "\n",
    "#TODO remove debug statement\n",
    "print(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define q-learning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG\n"
     ]
    }
   ],
   "source": [
    "class QAgent():\n",
    "    \n",
    "    def __init__(self, alpha, gamma, location_to_state, rewards, state_to_location, Q):\n",
    "        \"\"\" Initialize alpha, gamma, states, actions, rewards, and Q-values\n",
    "        \"\"\"\n",
    "        self.gamma = gamma  \n",
    "        self.alpha = alpha \n",
    "        \n",
    "        self.location_to_state = location_to_state\n",
    "        self.rewards = rewards\n",
    "        self.state_to_location = state_to_location\n",
    "        \n",
    "        self.Q = Q\n",
    "        \n",
    "    def training(self, start_location, end_location, iterations):\n",
    "        \"\"\"Training the system in the given environment to move from a start state to an end state\n",
    "        \"\"\"\n",
    "        rewards_new = np.copy(self.rewards)\n",
    "        \n",
    "        #set reward for end state to 100 to incentivize reaching desired end\n",
    "        ending_state = self.location_to_state[end_location]\n",
    "        rewards_new[ending_state, ending_state] = 100\n",
    "\n",
    "        #Loop for iterations\n",
    "        for i in range(iterations):\n",
    "            #Randomly pick a state to observe\n",
    "            current_state = np.random.randint(0,len(self.rewards)) \n",
    "            playable_actions = []\n",
    "\n",
    "            #Construct list of possible actions\n",
    "            for j in range(len(self.rewards)):\n",
    "                if rewards_new[current_state,j] > 0:\n",
    "                    playable_actions.append(j)\n",
    "\n",
    "            #Only run updates if observed state has performable actions\n",
    "            if len(playable_actions) > 0:\n",
    "                next_state = np.random.choice(playable_actions)\n",
    "\n",
    "                #Calculate temporal difference\n",
    "                TD = rewards_new[current_state,next_state] + \\\n",
    "                        self.gamma * self.Q[next_state, np.argmax(self.Q[next_state,])] - self.Q[current_state,next_state]\n",
    "\n",
    "                #updates Q-value using Bellman equation\n",
    "                self.Q[current_state,next_state] += self.alpha * TD\n",
    "\n",
    "        route = [start_location]\n",
    "        next_location = start_location\n",
    "        \n",
    "        # Get the route \n",
    "        return self.get_optimal_route(start_location, end_location, next_location, route, self.Q)\n",
    "        \n",
    "    # Get the optimal route\n",
    "    def get_optimal_route(self, start_location, end_location, next_location, route, Q):\n",
    "        \n",
    "        while(next_location != end_location):\n",
    "            starting_state = self.location_to_state[start_location]\n",
    "            next_state = np.argmax(Q[starting_state,])\n",
    "            next_location = self.state_to_location[next_state]\n",
    "            route.append(next_location)\n",
    "            start_location = next_location\n",
    "        \n",
    "        return route\n",
    "    \n",
    "#Take set of q-tables and average them into one q-table\n",
    "def qaverage(table_set):\n",
    "    num = 0\n",
    "    output_table = table_set[0].copy()\n",
    "    for i in range(len(table_set[0][0])):\n",
    "        for j in range(len(table_set[0])):\n",
    "            for k in range(len(table_set)):\n",
    "                num += table_set[k][j][i]\n",
    "            output_table[j][i] = num / len(table_set)\n",
    "            num = 0\n",
    "\n",
    "    return output_table\n",
    "    \n",
    "# Initialize parameters\n",
    "gamma = 0.75 # Discount factor (discounts previous rewards)\n",
    "alpha = 0.9 # Learning rate\n",
    "\n",
    "#TODO remove debug statement\n",
    "print(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q-learning\n",
    "\n",
    "So now that all the setup has been done, we can start our q-learning algorithm, then move on to processing its output.\n",
    "\n",
    "#### Define q-learning Execution Functions\n",
    "\n",
    "We need a couple of functions to handle our q-learning, since we need to execute multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle all q-learning for a given topology\n",
    "def qmaster(final_state, output_tables):\n",
    "    #array to store the final Q-Table of each 1000 iterations\n",
    "    qtables = []\n",
    "    for i in range(100):\n",
    "      qagent = QAgent(alpha, gamma, location_to_state, rewards,  state_to_location, \n",
    "                      np.array(np.zeros([len(location_to_state),len(location_to_state)])))\n",
    "      qagent.training('Start', final_state, 1000)\n",
    "      qtables.append(qagent.Q)\n",
    "\n",
    "    output_tables.append(qaverage(qtables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open File\n",
    "\n",
    "Now we open our file and format the data from the adjacency matrix to be compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG\n"
     ]
    }
   ],
   "source": [
    "#get topology from file\n",
    "with open(filename) as textFile:\n",
    "    rewards = np.array([[int(digit) for digit in line.strip().split(\",\")] for line in textFile])\n",
    "    \n",
    "#TODO remove debug statement\n",
    "print(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run q-learning algorithm\n",
    "\n",
    "Finally, we can run q-master and store the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an array to hold the outputs of q-master.\n",
    "averaged_tables = []\n",
    "\n",
    "#run qmaster for each ending state\n",
    "for i in range(endings):\n",
    "    qmaster('E' + str(i + 1), averaged_tables)\n",
    "\n",
    "#TODO remove debug statement\n",
    "#qmaster('E1', averaged_tables)\n",
    "print(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get weights\n",
    "\n",
    "Calculate and apply weights to each of the averaged q-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate weights\n",
    "def weight_calculator(layers):\n",
    "    #get slope\n",
    "    slope = 1 / (layers * layers)\n",
    "    #get sum\n",
    "    sum = 0\n",
    "    for i in range(layers):\n",
    "        sum += (i * slope)\n",
    "    \n",
    "    #get amount to add to equal 1\n",
    "    toAdd = (1 - sum) / layers\n",
    "    \n",
    "    #Finally, set up and return array of weights\n",
    "    weights = []\n",
    "    for i in range(layers):\n",
    "        weights.append((i * slope) + toAdd)\n",
    "        \n",
    "    #print(weights)\n",
    "    return weights\n",
    "\n",
    "#Apply weighting function to give high score to early states\n",
    "def apply_weights_helper(array, layers, endings):\n",
    "    for i in range(1, endings + 1):\n",
    "        for j in range(len(array[0])):\n",
    "            array[-1*i][j] = 0\n",
    "    \n",
    "    weights = weight_calculator(int(layers))\n",
    "    weights.reverse()\n",
    "    apply_weights(array, weights, 0, 0)\n",
    "    \n",
    "def apply_weights(array, weights, x, level):\n",
    "    for i in range(len(array[x])):\n",
    "        if(level < len(weights)):\n",
    "            array[x][i] = array[x][i] * weights[level]\n",
    "        if(array[x][i] > 0):\n",
    "            apply_weights(array, weights, i, (level + 1))\n",
    "            \n",
    "for i in range(len(averaged_tables)):\n",
    "    apply_weights_helper(averaged_tables[i], layers, endings)\n",
    "    \n",
    "print(averaged_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing\n",
    "\n",
    "Before we take the pairwise minkowski distance to get our score, we want to normalize our weighted q-tables.\n",
    "We can do this by running each subarray of each table through the Softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax implementation modified from\n",
    "#https://intellipaat.com/community/942/how-to-implement-the-softmax-function-in-python\n",
    "\n",
    "def softmax(x): \n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\" \n",
    "    e_x = np.exp(x - np.max(x)) \n",
    "    return (e_x / e_x.sum(axis=0)).tolist()\n",
    "\n",
    "def normalize(array, endings):\n",
    "    processedList = []\n",
    "    indices = []\n",
    "    pair = []\n",
    "    for i in range(len(array) - endings):\n",
    "        for j in range(len(array)):\n",
    "            if(array[i][j] > 0):\n",
    "                pair.append(i)\n",
    "                pair.append(j)\n",
    "                indices.append(pair.copy())\n",
    "                pair = []\n",
    "                processedList.append(array[i][j])\n",
    "        \n",
    "    processedList = softmax(processedList)\n",
    "    for j in range(len(indices)):\n",
    "        array[indices[j][0]][indices[j][1]] = processedList[j]\n",
    "        \n",
    "            \n",
    "#generates excel spreadsheet containing all q-tables in a given path\n",
    "def to_excel(qtables):\n",
    "    \"\"\"store data in excel\n",
    "    \"\"\"\n",
    "    workbook = xlsxwriter.Workbook(filename + '.xlsx')\n",
    "\n",
    "    #write each q-table to another worksheet\n",
    "    for i in range(len(qtables)):\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        for j in range(len(qtables[i])):\n",
    "            for k in range(len(qtables[i])):\n",
    "                worksheet.write(j, k, qtables[i][j][k])\n",
    "\n",
    "    workbook.close()\n",
    "            \n",
    "for i in range(len(averaged_tables)):\n",
    "    normalize(averaged_tables[i], endings)\n",
    "    to_excel(averaged_tables)\n",
    "    \n",
    "#TODO remove debug statement\n",
    "print(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Minkowski Distances and Output the Score\n",
    "\n",
    "We're finally ready to calculate the minkowski distance and output a meaningfulness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minkowski Distance implementation altered from\n",
    "#https://www.geeksforgeeks.org/minkowski-distance-python/\n",
    "\n",
    "#convert array into 1D vector for ease of manipulation\n",
    "def vectorize(input_array):\n",
    "    output_array = []\n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            output_array.append(input_array[i][j])\n",
    "            \n",
    "    return output_array\n",
    "\n",
    "#Calculate Minkowski distance between arrays\n",
    "  \n",
    "# Function distance between two points  \n",
    "# and calculate distance value to given \n",
    "# root value(p is root value) \n",
    "def p_root(value, root): \n",
    "      \n",
    "    root_value = 1 / float(root) \n",
    "    return round (Decimal(value) **\n",
    "             Decimal(root_value), 3) \n",
    "  \n",
    "def minkowski_distance(x, y, p_value): \n",
    "    # pass the p_root function to calculate \n",
    "    # all the values of vector in parallel \n",
    "    return (p_root(sum(pow(abs(a-b), p_value) \n",
    "            for a, b in zip(x, y)), p_value))\n",
    "\n",
    "#vectorize averaged tables\n",
    "vectors = []\n",
    "for i in range(len(averaged_tables)):\n",
    "    vectors.append(vectorize(averaged_tables[i]))\n",
    "    \n",
    "#calculate minkowski distances in a pairwise fashion\n",
    "distances = []\n",
    "acc = 0\n",
    "for i in range(len(averaged_tables) - 1):\n",
    "    for j in range(i + 1, len(vectors)):\n",
    "        distance = minkowski_distance(vectors[i], vectors[j], 1) / 2\n",
    "        distances.append(distance)\n",
    "        acc += distance\n",
    "\n",
    "print(acc / len(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
