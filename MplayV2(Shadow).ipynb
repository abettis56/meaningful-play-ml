{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meaningful Play Score Assigner V1\n",
    "Accepts a topology of choices in the form of several weighted adjacency matrices, each with a 1 for any viable connection, and a 999 for the desired ending. Then, it performs q-learning based calculations and outputs a score of meaningfulness based on the average of the pairwise weighted minkowski distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Q-Learning Class\n",
    "\n",
    "Define the functions for q-learning and for outputting the optimal path and q-tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent():\n",
    "    \n",
    "    def __init__(self, alpha, gamma, location_to_state, rewards, state_to_location, Q):\n",
    "        \"\"\" Initialize alpha, gamma, states, actions, rewards, and Q-values\n",
    "        \"\"\"\n",
    "        self.gamma = gamma  \n",
    "        self.alpha = alpha \n",
    "        \n",
    "        self.location_to_state = location_to_state\n",
    "        self.rewards = rewards\n",
    "        self.state_to_location = state_to_location\n",
    "        \n",
    "        self.Q = Q\n",
    "        \n",
    "    def training(self, start_location, end_location, iterations):\n",
    "        \"\"\"Training the system in the given environment to move from a start state to an end state\n",
    "        \"\"\"\n",
    "        rewards_new = np.copy(self.rewards)\n",
    "        \n",
    "        #set reward for end state to 999 to incentivize reaching desired end\n",
    "        ending_state = self.location_to_state[end_location]\n",
    "        rewards_new[ending_state, ending_state] = 999\n",
    "\n",
    "        #Loop for iterations\n",
    "        for i in range(iterations):\n",
    "            #Randomly pick a state to observe\n",
    "            current_state = np.random.randint(0,len(self.rewards)) \n",
    "            playable_actions = []\n",
    "\n",
    "            #Construct list of possible actions\n",
    "            for j in range(len(self.rewards)):\n",
    "                if rewards_new[current_state,j] > 0:\n",
    "                    playable_actions.append(j)\n",
    "\n",
    "            #Only run updates if observed state has performable actions\n",
    "            if len(playable_actions) > 0:\n",
    "                next_state = np.random.choice(playable_actions)\n",
    "\n",
    "                #Calculate temporal difference\n",
    "                TD = rewards_new[current_state,next_state] + \\\n",
    "                        self.gamma * self.Q[next_state, np.argmax(self.Q[next_state,])] - self.Q[current_state,next_state]\n",
    "\n",
    "                #updates Q-value using Bellman equation\n",
    "                self.Q[current_state,next_state] += self.alpha * TD\n",
    "\n",
    "        route = [start_location]\n",
    "        next_location = start_location\n",
    "        \n",
    "        # Get the route \n",
    "        return self.get_optimal_route(start_location, end_location, next_location, route, self.Q)\n",
    "        \n",
    "    # Get the optimal route\n",
    "    def get_optimal_route(self, start_location, end_location, next_location, route, Q):\n",
    "        \n",
    "        while(next_location != end_location):\n",
    "            starting_state = self.location_to_state[start_location]\n",
    "            next_state = np.argmax(Q[starting_state,])\n",
    "            next_location = self.state_to_location[next_state]\n",
    "            route.append(next_location)\n",
    "            start_location = next_location\n",
    "        \n",
    "        return route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "\n",
    "Get the input and then execute q-learning algorithm to get q-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the name of the topology .txt file you want to score: ShadowTopology1.txt\n",
      "[[   0.          691.63932699  695.09514446 ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " ...\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.         3993.35723221]]\n"
     ]
    }
   ],
   "source": [
    "#topology txt file to score\n",
    "filename = input(\"Please input the name of the topology .txt file you want to score: \")\n",
    "\n",
    "#get topology from file\n",
    "with open(filename) as textFile:\n",
    "    rewards = np.array([[int(digit) for digit in line.strip().split(\",\")] for line in textFile])\n",
    "    \n",
    "#list of averaged q-tables to take minkowski differences of\n",
    "averaged_tables = []\n",
    "\n",
    "# Define the states\n",
    "location_to_state = {\n",
    "    'Start' : 0,\n",
    "    '2-1' : 1,\n",
    "    '2-2' : 2,\n",
    "    '2-3' : 3,\n",
    "    '3-1' : 4,\n",
    "    '3-2' : 5,\n",
    "    '3-3' : 6,\n",
    "    '4-1' : 7,\n",
    "    '4-2' : 8,\n",
    "    '4-3' : 9,\n",
    "    '4-4' : 10,\n",
    "    '4-5' : 11,\n",
    "    '5-1' : 12,\n",
    "    '5-2' : 13,\n",
    "    '5-3' : 14,\n",
    "    '5-4' : 15,\n",
    "    '5-5' : 16,\n",
    "    '6-1' : 17,\n",
    "    '6-2' : 18,\n",
    "    '6-3' : 19,\n",
    "    '6-4' : 20,\n",
    "    '6-5' : 21,\n",
    "    'E1' : 22,\n",
    "    'E2' : 23,\n",
    "    'E3' : 24,\n",
    "    'E4' : 25,\n",
    "    'E5' : 26,\n",
    "    'E6' : 27,\n",
    "    'E7' : 28,\n",
    "    'E8' : 29,\n",
    "    'E9' : 30,\n",
    "    'E10' : 31\n",
    "}\n",
    "\n",
    "# Map indices to locations\n",
    "state_to_location = dict((state,location) for location,state in location_to_state.items())\n",
    "\n",
    "# Initialize parameters\n",
    "gamma = 0.75 # Discount factor (discounts previous rewards)\n",
    "alpha = 0.9 # Learning rate\n",
    "\n",
    "#generates excel spreadsheet containing all q-tables in a given path\n",
    "def to_excel(paths_taken, qtables, final_state):\n",
    "    \"\"\"store data in excel\n",
    "    \"\"\"\n",
    "    workbook = xlsxwriter.Workbook(filename + final_state + '.xlsx')\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    #write all paths taken into first worksheet\n",
    "    col = 0\n",
    "    for row, data in enumerate(paths_taken):\n",
    "        worksheet.write_row(row, col, data)\n",
    "\n",
    "    #write each q-table to another worksheet\n",
    "    for table, data in enumerate(qtables):\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        for row, data2 in enumerate(qtables[table]):\n",
    "            worksheet.write_row(row, col, data2)\n",
    "\n",
    "    workbook.close()\n",
    "    \n",
    "#Take set of q-tables and average them into one q-table\n",
    "def qaverage(table_set):\n",
    "    num = 0\n",
    "    output_table = table_set[0].copy()\n",
    "    for i in range(len(table_set[0][0])):\n",
    "        for j in range(len(table_set[0])):\n",
    "            for k in range(len(table_set)):\n",
    "                num += table_set[k][j][i]\n",
    "            output_table[j][i] = num / len(table_set)\n",
    "            num = 0\n",
    "            \n",
    "    return output_table\n",
    "\n",
    "#Handle all q-learning for a given topology\n",
    "def qmaster(final_state):\n",
    "    #array to store the final optimal path of each 1000 iterations\n",
    "    paths_taken = []\n",
    "    #array to store the final Q-Table of each 1000 iterations\n",
    "    qtables = []\n",
    "    for i in range(100):\n",
    "      qagent = QAgent(alpha, gamma, location_to_state, rewards,  state_to_location, \n",
    "                      np.array(np.zeros([len(location_to_state),len(location_to_state)])))\n",
    "      paths_taken.append(qagent.training('Start', final_state, 1000))\n",
    "      qtables.append(qagent.Q)\n",
    "\n",
    "    #output the current run to an excel file\n",
    "    to_excel(paths_taken, qtables, final_state)\n",
    "    averaged_tables.append(qaverage(qtables))\n",
    "\n",
    "#run qmaster for each ending state\n",
    "for i in range(10):\n",
    "    qmaster('E' + str(i + 1))\n",
    "    \n",
    "print(averaged_tables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Minkowski Difference\n",
    "\n",
    "Now that the averaged q-tables are stored, we can calculate the minkowski differences in a pairwise fashion, average them up, and then spit them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the number of non-ending layers your topology has: 6\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-12ca6e644657>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please input the number of non-ending layers your topology has: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveraged_tables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mapply_weights_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveraged_tables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveraged_tables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-12ca6e644657>\u001b[0m in \u001b[0;36mapply_weights_helper\u001b[1;34m(array, layers)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_calculator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mapply_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-12ca6e644657>\u001b[0m in \u001b[0;36mapply_weights\u001b[1;34m(array, weights, x, level)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mapply_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#Calculate Minkowski distance between arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m<ipython-input-7-12ca6e644657>\u001b[0m in \u001b[0;36mapply_weights\u001b[1;34m(array, weights, x, level)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mapply_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#Calculate Minkowski distance between arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "#altered from\n",
    "#https://www.geeksforgeeks.org/minkowski-distance-python/\n",
    "\n",
    "#convert array into 1D vector for ease of manipulation\n",
    "def vectorize(input_array):\n",
    "    output_array = []\n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            output_array.append(input_array[i][j])\n",
    "            \n",
    "    return output_array\n",
    "\n",
    "def weight_calculator(layers):\n",
    "    #get slope\n",
    "    slope = 1 / (layers * layers)\n",
    "    #get sum\n",
    "    sum = 0\n",
    "    for i in range(layers):\n",
    "        sum += (i * slope)\n",
    "    \n",
    "    #get amount to add to equal 1\n",
    "    toAdd = (1 - sum) / layers\n",
    "    \n",
    "    #Finally, set up and return array of weights\n",
    "    weights = []\n",
    "    for i in range(layers):\n",
    "        weights.append((i * slope) + toAdd)\n",
    "        \n",
    "    #print(weights)\n",
    "    return weights\n",
    "\n",
    "#Apply weighting function to give high score to early states\n",
    "def apply_weights_helper(array, layers):\n",
    "    weights = weight_calculator(int(layers))\n",
    "    weights.reverse()\n",
    "    apply_weights(array, weights, 0, 0)\n",
    "    \n",
    "def apply_weights(array, weights, x, level):\n",
    "    for i in range(len(array[x])):\n",
    "        if(level < len(weights)):\n",
    "            array[x][i] = array[x][i] * weights[level]\n",
    "        if(array[x][i] > 0):\n",
    "            apply_weights(array, weights, i, (level + 1))\n",
    "            \n",
    "#Calculate Minkowski distance between arrays\n",
    "  \n",
    "# Function distance between two points  \n",
    "# and calculate distance value to given \n",
    "# root value(p is root value) \n",
    "def p_root(value, root): \n",
    "      \n",
    "    root_value = 1 / float(root) \n",
    "    return round (Decimal(value) **\n",
    "             Decimal(root_value), 3) \n",
    "  \n",
    "def minkowski_distance(x, y, p_value): \n",
    "    # pass the p_root function to calculate \n",
    "    # all the values of vector in parallel \n",
    "    return (p_root(sum(pow(abs(a-b), p_value) \n",
    "            for a, b in zip(x, y)), p_value))\n",
    "\n",
    "#vectorize averaged tables and apply weights\n",
    "vectors = []\n",
    "layers = input(\"Please input the number of non-ending layers your topology has: \")\n",
    "for i in range(len(averaged_tables)):\n",
    "    apply_weights_helper(averaged_tables[i], layers)\n",
    "    vectors.append(vectorize(averaged_tables[i]))\n",
    "    \n",
    "#calculate minkowski distances in a pairwise fashion\n",
    "distances = []\n",
    "acc = 0\n",
    "for i in range(len(averaged_tables) - 1):\n",
    "    for j in range(i + 1, len(vectors)):\n",
    "        distance = minkowski_distance(vectors[i], vectors[j], 1)\n",
    "        distances.append(distance)\n",
    "        acc += distance\n",
    "\n",
    "print(acc / len(distances))\n",
    "#print(minkowski_distance(vectors[0], vectors[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
