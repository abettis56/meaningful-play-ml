{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meaningful Play Score Assigner V1\n",
    "Accepts a topology of choices in the form of several weighted adjacency matrices, each with a 1 for any viable connection, and a 999 for the desired ending. Then, it performs q-learning based calculations and outputs a score of meaningfulness based on the average of the pairwise weighted minkowski distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Q-Learning Class\n",
    "\n",
    "Define the functions for q-learning and for outputting the optimal path and q-tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent():\n",
    "    \n",
    "    def __init__(self, alpha, gamma, location_to_state, rewards, state_to_location, Q):\n",
    "        \"\"\" Initialize alpha, gamma, states, actions, rewards, and Q-values\n",
    "        \"\"\"\n",
    "        self.gamma = gamma  \n",
    "        self.alpha = alpha \n",
    "        \n",
    "        self.location_to_state = location_to_state\n",
    "        self.rewards = rewards\n",
    "        self.state_to_location = state_to_location\n",
    "        \n",
    "        self.Q = Q\n",
    "        \n",
    "    def training(self, start_location, end_location, iterations):\n",
    "        \"\"\"Training the system in the given environment to move from a start state to an end state\n",
    "        \"\"\"\n",
    "        rewards_new = np.copy(self.rewards)\n",
    "        \n",
    "        #set reward for end state to 999 to incentivize reaching desired end\n",
    "        ending_state = self.location_to_state[end_location]\n",
    "        rewards_new[ending_state, ending_state] = 999\n",
    "\n",
    "        #Loop for iterations\n",
    "        for i in range(iterations):\n",
    "            #Randomly pick a state to observe\n",
    "            current_state = np.random.randint(0,len(self.rewards)) \n",
    "            playable_actions = []\n",
    "\n",
    "            #Construct list of possible actions\n",
    "            for j in range(len(self.rewards)):\n",
    "                if rewards_new[current_state,j] > 0:\n",
    "                    playable_actions.append(j)\n",
    "\n",
    "            #Only run updates if observed state has performable actions\n",
    "            if len(playable_actions) > 0:\n",
    "                next_state = np.random.choice(playable_actions)\n",
    "\n",
    "                #Calculate temporal difference\n",
    "                TD = rewards_new[current_state,next_state] + \\\n",
    "                        self.gamma * self.Q[next_state, np.argmax(self.Q[next_state,])] - self.Q[current_state,next_state]\n",
    "                #compare overlapping Q values\n",
    "                #even w/o same value could encode same policy (where max/mins are)\n",
    "\n",
    "                #updates Q-value using Bellman equation\n",
    "                self.Q[current_state,next_state] += self.alpha * TD\n",
    "\n",
    "        route = [start_location]\n",
    "        next_location = start_location\n",
    "        \n",
    "        # Get the route \n",
    "        return self.get_optimal_route(start_location, end_location, next_location, route, self.Q)\n",
    "        \n",
    "    # Get the optimal route\n",
    "    def get_optimal_route(self, start_location, end_location, next_location, route, Q):\n",
    "        \n",
    "        while(next_location != end_location):\n",
    "            starting_state = self.location_to_state[start_location]\n",
    "            next_state = np.argmax(Q[starting_state,])\n",
    "            #episilon?\n",
    "            next_location = self.state_to_location[next_state]\n",
    "            route.append(next_location)\n",
    "            start_location = next_location\n",
    "        \n",
    "        return route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "\n",
    "Get the input and then execute q-learning algorithm to get q-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the name of the topology .txt file you want to score: NoIntegrated.txt\n",
      "[[0.00000000e+00 9.50186950e+02 9.49823439e+02 9.50463329e+02\n",
      "  9.50458178e+02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.26639695e+03 1.26590564e+03 1.26598249e+03\n",
      "  1.26637930e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.26603865e+03 1.26537074e+03 1.26606346e+03\n",
      "  1.26253778e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.26598976e+03 1.26627405e+03 1.26562278e+03\n",
      "  1.26634914e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.26596932e+03 1.26609394e+03 1.26489768e+03\n",
      "  1.26518191e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.68630621e+03 1.68612669e+03 1.68718402e+03\n",
      "  1.68744386e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.68655857e+03 1.68549843e+03 1.68716538e+03\n",
      "  1.68561262e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.68673098e+03 1.68689256e+03 1.68601013e+03\n",
      "  1.68764222e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.68714502e+03 1.68640137e+03 1.68722612e+03\n",
      "  1.68582913e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.24558442e+03 2.24236291e+03 2.24677954e+03\n",
      "  2.24785711e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.24680474e+03 2.24726036e+03 2.24679697e+03\n",
      "  2.24821659e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.24465863e+03 2.24760104e+03 2.24705417e+03\n",
      "  2.24739227e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.24448769e+03 2.22327219e+03 2.24606255e+03\n",
      "  2.24525911e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99999783e-01 9.99887655e-01 9.99999688e-01\n",
      "  2.99719175e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99999857e-01 9.99999743e-01 9.99999787e-01\n",
      "  2.99738192e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99999766e-01 9.99999923e-01 9.99998774e-01\n",
      "  2.99691411e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99999863e-01 9.99879866e-01 9.99988985e-01\n",
      "  2.99769230e+03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.99591206e+03]]\n"
     ]
    }
   ],
   "source": [
    "#topology txt file to score\n",
    "filename = input(\"Please input the name of the topology .txt file you want to score: \")\n",
    "\n",
    "#get topology from file\n",
    "with open(filename) as textFile:\n",
    "    rewards = np.array([[int(digit) for digit in line.strip().split(\",\")] for line in textFile])\n",
    "    \n",
    "#list of averaged q-tables to take minkowski differences of\n",
    "averaged_tables = []\n",
    "\n",
    "# Define the states\n",
    "location_to_state = {\n",
    "    'Start' : 0,\n",
    "    '1D' : 1,\n",
    "    '1N1' : 2,\n",
    "    '1N2' : 3,\n",
    "    '1C' : 4,\n",
    "    '2D' : 5,\n",
    "    '2N1' : 6,\n",
    "    '2N2' : 7,\n",
    "    '2C' : 8,\n",
    "    '3D' : 9,\n",
    "    '3N1' : 10,\n",
    "    '3N2' : 11,\n",
    "    '3C' : 12,\n",
    "    '4D' : 13,\n",
    "    '4N1' : 14,\n",
    "    '4N2' : 15,\n",
    "    '4C' : 16,\n",
    "    'E1' : 17,\n",
    "    'E2' : 18,\n",
    "    'E3' : 19,\n",
    "    'E4' : 20\n",
    "}\n",
    "\n",
    "# Map indices to locations\n",
    "state_to_location = dict((state,location) for location,state in location_to_state.items())\n",
    "\n",
    "# Initialize parameters\n",
    "gamma = 0.75 # Discount factor (discounts previous rewards)\n",
    "alpha = 0.9 # Learning rate\n",
    "\n",
    "#generates excel spreadsheet containing all q-tables in a given path\n",
    "def to_excel(paths_taken, qtables, final_state):\n",
    "    \"\"\"store data in excel\n",
    "    \"\"\"\n",
    "    workbook = xlsxwriter.Workbook(filename + final_state + '.xlsx')\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    #write all paths taken into first worksheet\n",
    "    col = 0\n",
    "    for row, data in enumerate(paths_taken):\n",
    "        worksheet.write_row(row, col, data)\n",
    "\n",
    "    #write each q-table to another worksheet\n",
    "    for table, data in enumerate(qtables):\n",
    "        worksheet = workbook.add_worksheet()\n",
    "        for row, data2 in enumerate(qtables[table]):\n",
    "            worksheet.write_row(row, col, data2)\n",
    "\n",
    "    workbook.close()\n",
    "    \n",
    "#Take set of q-tables and average them into one q-table\n",
    "def qaverage(table_set):\n",
    "    num = 0\n",
    "    output_table = table_set[0].copy()\n",
    "    for i in range(len(table_set[0][0])):\n",
    "        for j in range(len(table_set[0])):\n",
    "            for k in range(len(table_set)):\n",
    "                num += table_set[k][j][i]\n",
    "            output_table[j][i] = num / len(table_set)\n",
    "            num = 0\n",
    "            \n",
    "    return output_table\n",
    "\n",
    "#Handle all q-learning for a given topology\n",
    "def qmaster(final_state):\n",
    "    #array to store the final optimal path of each 1000 iterations\n",
    "    paths_taken = []\n",
    "    #array to store the final Q-Table of each 1000 iterations\n",
    "    qtables = []\n",
    "    for i in range(100):\n",
    "      qagent = QAgent(alpha, gamma, location_to_state, rewards,  state_to_location, np.array(np.zeros([21,21])))\n",
    "      paths_taken.append(qagent.training('Start', final_state, 1000))\n",
    "      qtables.append(qagent.Q)\n",
    "\n",
    "    #output the current run to an excel file\n",
    "    to_excel(paths_taken, qtables, final_state)\n",
    "    averaged_tables.append(qaverage(qtables))\n",
    "\n",
    "#run qmaster for each file name input\n",
    "for i in range(4):\n",
    "    qmaster('E' + str(i + 1))\n",
    "    \n",
    "print(averaged_tables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Minkowski Difference\n",
    "\n",
    "Now that the averaged q-tables are stored, we can calculate the minkowski differences in a pairwise fashion, average them up, and then spit them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2888.7105\n",
      "2886.399\n"
     ]
    }
   ],
   "source": [
    "#altered from\n",
    "#https://www.geeksforgeeks.org/minkowski-distance-python/\n",
    "\n",
    "#convert array into 1D vector for ease of manipulation\n",
    "def vectorize(input_array):\n",
    "    output_array = []\n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            output_array.append(input_array[i][j])\n",
    "            \n",
    "    return output_array\n",
    "\n",
    "#Apply weighting function to give high score to early states\n",
    "def apply_weights(array):\n",
    "    #These values can be adjusted to change weights\n",
    "    #----------------------------------------------\n",
    "    level_one = 0.28\n",
    "    level_two = 0.24\n",
    "    level_three = 0.2\n",
    "    level_four = 0.16\n",
    "    level_five = 0.12\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    for i in range(441):\n",
    "        #check what the i index would be in a 21x21 2D array\n",
    "        index = i // 21\n",
    "\n",
    "        if index == 0:\n",
    "            array[i] = array[i] * level_one\n",
    "        elif index in range(1, 5):\n",
    "            array[i] = array[i] * level_two\n",
    "        elif index in range(5, 9):\n",
    "            array[i] = array[i] * level_three\n",
    "        elif index in range(9, 13):\n",
    "            array[i] = array[i] * level_four\n",
    "        elif index in range(13, 17):\n",
    "            array[i] = array[i] * level_five\n",
    "        elif index in range(17, 21):\n",
    "            array[i] = 0\n",
    "            \n",
    "#Calculate Minkowski distance between arrays\n",
    "  \n",
    "# Function distance between two points  \n",
    "# and calculate distance value to given \n",
    "# root value(p is root value) \n",
    "def p_root(value, root): \n",
    "      \n",
    "    root_value = 1 / float(root) \n",
    "    return round (Decimal(value) **\n",
    "             Decimal(root_value), 3) \n",
    "  \n",
    "def minkowski_distance(x, y, p_value): \n",
    "    # pass the p_root function to calculate \n",
    "    # all the values of vector in parallel \n",
    "    return (p_root(sum(pow(abs(a-b), p_value) \n",
    "            for a, b in zip(x, y)), p_value))\n",
    "\n",
    "#vectorize averaged tables and apply weights\n",
    "vectors = []\n",
    "for i in range(len(averaged_tables)):\n",
    "    vectors.append(vectorize(averaged_tables[i]))\n",
    "    vectorize(averaged_tables[i])\n",
    "    apply_weights(vectors[i])\n",
    "    \n",
    "#calculate minkowski distances in a pairwise fashion\n",
    "distances = []\n",
    "acc = 0\n",
    "for i in range(len(averaged_tables) - 1):\n",
    "    for j in range(i + 1, len(vectors)):\n",
    "        distance = minkowski_distance(vectors[i], vectors[j], 1)\n",
    "        distances.append(distance)\n",
    "        acc += distance\n",
    "\n",
    "print(acc / len(distances))\n",
    "print(minkowski_distance(vectors[0], vectors[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
